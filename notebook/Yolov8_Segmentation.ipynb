{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/febrahim-driod/hello-world/blob/master/notebook/Yolov8_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6bc66b-b814-4c3f-ebae-b6ac2f278e7e"
      },
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "!pip install roboflow --quiet\n",
        "!pip install clearml --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.58 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 25.6/78.2 GB disk)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.7 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "from clearml import Task\n",
        "\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "DTjhFMyhdWSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f957bf16-0407-487f-8bf6-e259c8451508"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_type='detection'\n",
        "#model_type='body_parts'\n",
        "#model_type='severity'\n",
        "model_type='damage_type'\n",
        "\n",
        "WEIGHTS_PATH = f\"{HOME}/yolov8l-seg.pt\"\n",
        "TASK='segment'\n",
        "IMGSZ=640\n",
        "BATCH_SIZE=16\n",
        "WORKERS=8\n",
        "PATIENCE=5\n",
        "\n",
        "#roboflow\n",
        "#workspace=\"sinfo\"\n",
        "#workspace=\"fizzy\"\n",
        "workspace=\"ae-43fv6\"\n",
        "\n",
        "if model_type==\"detection\":\n",
        "   EPOCH=30\n",
        "   PROJECT_NAME=\"yolov8_damage_detection\"\n",
        "   RUN_NAME=\"train_seg_\"+str(EPOCH)+\"_epoch\"\n",
        "elif model_type==\"body_parts\":\n",
        "   EPOCH=50\n",
        "   PROJECT_NAME=\"yolov8_body_parts\"\n",
        "   RUN_NAME=\"train_seg_\"+str(EPOCH)+\"_epoch\"\n",
        "elif model_type==\"severity\":\n",
        "   EPOCH=50\n",
        "   PROJECT_NAME=\"yolov8_severity\"\n",
        "   RUN_NAME=\"train_seg_\"+str(EPOCH)+\"_epoch\"\n",
        "elif model_type==\"damage_type\":\n",
        "   EPOCH=50\n",
        "   PROJECT_NAME=\"yolov8_damage_type\"\n",
        "   RUN_NAME=\"train_seg_\"+str(EPOCH)+\"_epoch\"\n",
        "   "
      ],
      "metadata": {
        "id": "tp60Ei_Aa_t7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "if workspace==\"sinfo\":\n",
        "  apikey=\"P5E6JhfkeiA1nAdZAWnB\"\n",
        "if workspace==\"fizzy\":\n",
        "  apikey=\"BY0NkaVcAVgAKtFokphd\"\n",
        "if workspace==\"ae-43fv6\":\n",
        "  apikey=\"4Bp3oYulJzO2eVypsB2l\"\n",
        "\n",
        "\n",
        "rf = Roboflow(api_key=apikey)\n",
        "if model_type==\"detection\":\n",
        "  if workspace==\"sinfo\":\n",
        "    project = rf.workspace(workspace).project(\"car_damage-4xqh8\")\n",
        "    dataset = project.version(6).download(\"yolov8\")\n",
        "    DATA_FOLDER='car_damage-6'\n",
        "  DATA_YAML_PATH= f\"{HOME}/{DATA_FOLDER}/data.yaml\"\n",
        "elif model_type==\"body_parts\":\n",
        "  project = rf.workspace(workspace).project(\"car-body-parts-p025a\")\n",
        "  dataset = project.version(5).download(\"yolov8\")\n",
        "  DATA_FOLDER='car-body-parts-5'\n",
        "  DATA_YAML_PATH= f\"{HOME}/{DATA_FOLDER}/data.yaml\"\n",
        "elif model_type==\"severity\":\n",
        "  project = rf.workspace(workspace).project(\"car-body-parts-p025a\")\n",
        "  dataset = project.version(5).download(\"yolov8\")\n",
        "  DATA_FOLDER='car-damage-severity-2'\n",
        "  DATA_YAML_PATH= f\"{HOME}/{DATA_FOLDER}/data.yaml\"\n",
        "elif model_type==\"damage_type\":\n",
        "  if workspace==\"sinfo\":\n",
        "    project = rf.workspace(workspace).project(\"car-damage-type\")\n",
        "    dataset = project.version(1).download(\"yolov8\")\n",
        "    DATA_FOLDER='car-damage-type-1'\n",
        "  elif  workspace==\"fizzy\":\n",
        "    project = rf.workspace(workspace).project(\"damage-type-nbmqw\")\n",
        "    dataset = project.version(3).download(\"yolov8\")\n",
        "    DATA_FOLDER='Damage-Type-3'\n",
        "  elif workspace==\"ae-43fv6\":\n",
        "    project = rf.workspace(workspace).project(\"damage-type-nogzj\")\n",
        "    dataset = project.version(4).download(\"yolov8\")\n",
        "    DATA_FOLDER='Damage-Type-4'\n",
        "  DATA_YAML_PATH= f\"{HOME}/{DATA_FOLDER}/data.yaml\"\n"
      ],
      "metadata": {
        "id": "-6KSPpfndo2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fdd1a9c-1b91-4bc8-e5fa-61b08b0b3201"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics<=8.0.20 is required but found version=8.0.58, to fix: `pip install ultralytics<=8.0.20`\n",
            "Exporting format yolov8 in progress : 85.0%\n",
            "Version export complete for yolov8 format\n",
            "Downloading Dataset Version Zip in Damage-Type-3 to yolov8: 100% [120526896 / 120526896] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Damage-Type-3 in yolov8:: 100%|██████████| 4864/4864 [00:01<00:00, 2656.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "# colob_notebook\n",
        "%env CLEARML_API_ACCESS_KEY=AMY0O903Z5A7KN5FETFJ\n",
        "%env CLEARML_API_SECRET_KEY=y7hUwY62xMFWwADGFWzKd33C2b8C4f1AxTDymedak5lQFzmbJg\n",
        "\n",
        "task = Task.init(project_name=PROJECT_NAME, task_name=RUN_NAME)\n"
      ],
      "metadata": {
        "id": "qDxE57EKe8VR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da610e7f-3e16-4dfa-c257-f1383451df10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CLEARML_WEB_HOST=https://app.clear.ml\n",
            "env: CLEARML_API_HOST=https://api.clear.ml\n",
            "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
            "env: CLEARML_API_ACCESS_KEY=AMY0O903Z5A7KN5FETFJ\n",
            "env: CLEARML_API_SECRET_KEY=y7hUwY62xMFWwADGFWzKd33C2b8C4f1AxTDymedak5lQFzmbJg\n",
            "ClearML Task: created new task id=1326d8878f1e460c89088c5f163e85a3\n",
            "ClearML results page: https://app.clear.ml/projects/41a3e34a97974ba28082649ce517fd40/experiments/1326d8878f1e460c89088c5f163e85a3/output/log\n",
            "2023-03-31 08:40:03,145 - clearml.Task - INFO - Storing jupyter notebook directly as code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX"
      },
      "source": [
        "# Run inference on an image with YOLOv8n-seg\n",
        "#!yolo predict model=yolov8l-seg.pt source='https://ultralytics.com/images/zidane.jpg' box=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://roboflow.com/?ref=ultralytics\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd57f1a-9a36-4a90-b344-f7b7d42a4ddb"
      },
      "source": [
        "# Train YOLOv8l on Custom Data\n",
        "!yolo mode=train \\\n",
        "      model=$WEIGHTS_PATH \\\n",
        "      data=$DATA_YAML_PATH \\\n",
        "      epochs=$EPOCH \\\n",
        "      imgsz=$IMGSZ \\\n",
        "      task=$TASK \\\n",
        "      project=$PROJECT_NAME \\\n",
        "      name=$RUN_NAME \\\n",
        "      batch=$BATCH_SIZE \\\n",
        "      workers=$WORKERS    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.58 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=segment, mode=train, model=/content/yolov8l-seg.pt, data=/content/Damage-Type-3/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=yolov8_damage_type, name=train_seg_50_epoch, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=yolov8_damage_type/train_seg_50_epoch2\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.Conv                  [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.C2f                   [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.C2f                   [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.C2f                   [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.C2f                   [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.C2f                   [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.C2f                   [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   7892092  ultralytics.nn.modules.Segment               [4, 32, 256, [256, 512, 512]] \n",
            "YOLOv8l-seg summary: 401 layers, 45939132 parameters, 45939116 gradients, 220.8 GFLOPs\n",
            "\n",
            "Transferred 651/657 items from pretrained weights\n",
            "2023-03-31 08:46:26.065455: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-31 08:46:27.039274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov8_damage_type/train_seg_50_epoch2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 106 weight(decay=0.0), 117 weight(decay=0.0005), 116 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Damage-Type-3/train/labels.cache... 1716 images, 0 backgrounds, 0 corrupt: 100% 1716/1716 [00:00<?, ?it/s]\n",
            "/content/Damage-Type-3/train/images/stock-photo-car-body-side-damage-after-an-road-traffic-accident-copy-space-1034226592_jpg.rf.bec7068dc7d508ebda384a0e426131bd.jpg 1 0\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 3169, len(boxes) = 3170. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Damage-Type-3/valid/labels.cache... 468 images, 0 backgrounds, 0 corrupt: 100% 468/468 [00:00<?, ?it/s]\n",
            "/content/Damage-Type-3/valid/images/stock-photo-car-body-side-damage-after-an-road-traffic-accident-copy-space-1034226592_jpg.rf.022a7f29a9db8c026c596db6e8a72f4b.jpg 1 0\n",
            "/content/Damage-Type-3/valid/images/stock-photo-car-body-side-damage-after-an-road-traffic-accident-copy-space-1034226592_jpg.rf.0638e8672301db2cc33ea79dc7f106ba.jpg 1 0\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 787, len(boxes) = 789. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to yolov8_damage_type/train_seg_50_epoch2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov8_damage_type/train_seg_50_epoch2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/108 [00:02<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/v8/segment/train.py\", line 82, in __call__\n",
            "    targets = torch.cat((batch_idx, batch['cls'].view(-1, 1), batch['bboxes'].to(dtype)), 1)\n",
            "RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 61 but got size 0 for tensor number 1 in the list.\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 318, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/model.py\", line 329, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/trainer.py\", line 191, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/trainer.py\", line 320, in _do_train\n",
            "    self.loss, self.loss_items = self.criterion(preds, batch)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/v8/segment/train.py\", line 40, in criterion\n",
            "    return self.compute_loss(preds, batch)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/v8/segment/train.py\", line 87, in __call__\n",
            "    raise TypeError('ERROR ❌ segment dataset incorrectly formatted or not a segment dataset.\\n'\n",
            "TypeError: ERROR ❌ segment dataset incorrectly formatted or not a segment dataset.\n",
            "This error can occur when incorrectly training a 'segment' model on a 'detect' dataset, i.e. 'yolo train model=yolov8n-seg.pt data=coco128.yaml'.\n",
            "Verify your dataset is a correctly formatted 'segment' dataset using 'data=coco128-seg.yaml' as an example.\n",
            "See https://docs.ultralytics.com/tasks/segment/ for help.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "display(Image(filename=f'/content/{PROJECT_NAME}/{RUN_NAME}/confusion_matrix.png'))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "Xub6krqMsf57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training metrics\n",
        "display(Image(filename=f'/content/{PROJECT_NAME}/{RUN_NAME}/results.png'))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "HElCh6QftJXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imageName in glob.glob(f'/content/{PROJECT_NAME}/{RUN_NAME}/train_*.jpg')[:2]:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QPLJEpqXppWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imageName in glob.glob(f'/content/{PROJECT_NAME}/{RUN_NAME}/val_*.jpg')[:2]:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "4q-4bZ6LrQX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Predict\n",
        "Predict a model's accuracy on the dataset's `test` splits. "
      ],
      "metadata": {
        "id": "VF17iJXgtChp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BEST_WEIGHTS_PATH=f'/content/{PROJECT_NAME}/{RUN_NAME}/weights/best.pt'\n",
        "TEST_SOURCE_PATH=f'/content/{DATA_FOLDER}/test/images'\n",
        "\n",
        "!yolo task=$TASK \\\n",
        "      mode=predict \\\n",
        "      model= $BEST_WEIGHTS_PATH \\\n",
        "      source= $TEST_SOURCE_PATH \\\n",
        "      show=False \\\n",
        "      imgsz=$IMGSZ \\\n",
        "      project=$PROJECT_NAME \\\n",
        "      name=$RUN_NAME \\\n",
        "      hide_labels=True \\\n",
        "      conf=0.40 \\\n",
        "      save=True \\\n",
        "      box=False"
      ],
      "metadata": {
        "id": "4XDCTSF8tdLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for imageName in glob.glob(f'/content/{PROJECT_NAME}/{RUN_NAME}/*.jpg')[:5]:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "5Q33ZXT-t9A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kpiRmv66gOZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Export\n",
        "\n",
        "Export a YOLOv8 model to any supported format with the `format` argument, i.e. `format=onnx`.\n",
        "\n",
        "- 💡 ProTip: Export to [ONNX](https://onnx.ai/) or [OpenVINO](https://docs.openvino.ai/latest/index.html) for up to 3x CPU speedup.  \n",
        "- 💡 ProTip: Export to [TensorRT](https://developer.nvidia.com/tensorrt) for up to 5x GPU speedup.\n",
        "\n",
        "\n",
        "| Format                                                                     | `format=`          | Model                     |\n",
        "|----------------------------------------------------------------------------|--------------------|---------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                            | -                  | `yolov8n.pt`              |\n",
        "| [TorchScript](https://pytorch.org/docs/stable/jit.html)                    | `torchscript`      | `yolov8n.torchscript`     |\n",
        "| [ONNX](https://onnx.ai/)                                                   | `onnx`             | `yolov8n.onnx`            |\n",
        "| [OpenVINO](https://docs.openvino.ai/latest/index.html)                     | `openvino`         | `yolov8n_openvino_model/` |\n",
        "| [TensorRT](https://developer.nvidia.com/tensorrt)                          | `engine`           | `yolov8n.engine`          |\n",
        "| [CoreML](https://github.com/apple/coremltools)                             | `coreml`           | `yolov8n.mlmodel`         |\n",
        "| [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model)      | `saved_model`      | `yolov8n_saved_model/`    |\n",
        "| [TensorFlow GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`               | `yolov8n.pb`              |\n",
        "| [TensorFlow Lite](https://www.tensorflow.org/lite)                         | `tflite`           | `yolov8n.tflite`          |\n",
        "| [TensorFlow Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | `edgetpu`          | `yolov8n_edgetpu.tflite`  |\n",
        "| [TensorFlow.js](https://www.tensorflow.org/js)                             | `tfjs`             | `yolov8n_web_model/`      |\n",
        "| [PaddlePaddle](https://github.com/PaddlePaddle)                            | `paddle`           | `yolov8n_paddle_model/`   |\n",
        "\n"
      ],
      "metadata": {
        "id": "nPZZeNrLCQG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=$BEST_WEIGHTS_PATH format=onnx"
      ],
      "metadata": {
        "id": "CYIjW4igCjqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Close clearML experiment\n",
        "task.close()"
      ],
      "metadata": {
        "id": "DIGEnki6uEzK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}