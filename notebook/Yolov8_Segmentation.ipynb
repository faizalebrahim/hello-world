{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/febrahim-driod/hello-world/blob/master/notebook/Yolov8_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dedb852-01fd-48c9-988d-a88460b502ca"
      },
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "!pip install roboflow --quiet\n",
        "!pip install clearml --quiet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.80 🚀 Python-3.9.16 torch-2.0.0+cu118 CPU\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 23.2/107.7 GB disk)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "from clearml import Task\n",
        "\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "DTjhFMyhdWSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c416420b-742a-4672-c6f1-433181065b75"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model_type='detection'\n",
        "#model_type='body_parts'\n",
        "#model_type='severity'\n",
        "#model_type='damage_type'\n",
        "model_type='logo_detection'\n",
        "WEIGHTS_PATH = f\"{HOME}/yolov8l-seg.pt\"\n",
        "TASK='segment'\n",
        "IMGSZ=640\n",
        "BATCH_SIZE=16\n",
        "WORKERS=8\n",
        "PATIENCE=10\n",
        "\n",
        "#roboflow\n",
        "#workspace=\"sinfo\"\n",
        "#workspace=\"fizzy\"\n",
        "workspace=\"ae-43fv6\"\n",
        "\n",
        "if model_type==\"detection\":\n",
        "   EPOCH=30\n",
        "   PROJECT_NAME=\"yolov8_damage_detection\"\n",
        "   RUN_NAME=\"train_seg_\"+str(EPOCH)+\"_epoch\"\n",
        "elif model_type==\"body_parts\":\n",
        "   EPOCH=100\n",
        "   PROJECT_NAME=\"yolov8_body_parts\"\n",
        "   RUN_NAME=\"train_seg_\"+str(EPOCH)+\"_epoch\"\n",
        "elif model_type==\"severity\":\n",
        "   EPOCH=100\n",
        "   PROJECT_NAME=\"yolov8_severity\"\n",
        "   RUN_NAME=\"train_seg_\"+str(EPOCH)+\"_epoch\"\n",
        "elif model_type==\"damage_type\":\n",
        "   EPOCH=50\n",
        "   PROJECT_NAME=\"yolov8_damage_type\"\n",
        "   RUN_NAME=\"train_seg_\"+str(EPOCH)+\"_epoch\"\n",
        "elif model_type==\"logo_detection\":\n",
        "   EPOCH=50\n",
        "   PROJECT_NAME=\"yolov8_logo_detection\"\n",
        "   RUN_NAME=\"train_seg_\"+str(EPOCH)+\"_epoch\""
      ],
      "metadata": {
        "id": "tp60Ei_Aa_t7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "\n",
        "if workspace==\"sinfo\":\n",
        "  apikey=\"P5E6JhfkeiA1nAdZAWnB\" #Github\n",
        "if workspace==\"fizzy\":             \n",
        "  apikey=\"BY0NkaVcAVgAKtFokphd\" #Ayesha Ibrahim\n",
        "if workspace==\"ae-43fv6\":\n",
        "  apikey=\"4Bp3oYulJzO2eVypsB2l\" #Ayesha Ebrahim\n",
        "\n",
        "\n",
        "rf = Roboflow(api_key=apikey)\n",
        "if model_type==\"detection\":\n",
        "  if workspace==\"sinfo\":\n",
        "    project = rf.workspace(workspace).project(\"car_damage-4xqh8\")\n",
        "    dataset = project.version(6).download(\"yolov8\")\n",
        "    DATA_FOLDER='car_damage-6'\n",
        "  DATA_YAML_PATH= f\"{HOME}/{DATA_FOLDER}/data.yaml\"\n",
        "elif model_type==\"body_parts\":\n",
        "  if workspace==\"sinfo\":\n",
        "    project = rf.workspace(workspace).project(\"car-body-parts-p025a\")\n",
        "    dataset = project.version(5).download(\"yolov8\")\n",
        "    DATA_FOLDER='car-body-parts-5'\n",
        "  elif workspace==\"ae-43fv6\": \n",
        "    project = rf.workspace(\"ae-43fv6\").project(\"body-parts-cq3al\")\n",
        "    dataset = project.version(2).download(\"yolov8\")\n",
        "    DATA_FOLDER='Body-Parts-2'\n",
        "  DATA_YAML_PATH= f\"{HOME}/{DATA_FOLDER}/data.yaml\"\n",
        "elif model_type==\"severity\":\n",
        "  if workspace==\"sinfo\":\n",
        "    project = rf.workspace(workspace).project(\"car-damage-severity\")\n",
        "    dataset = project.version(2).download(\"yolov8\")\n",
        "    DATA_FOLDER='car-damage-severity-2'\n",
        "  elif workspace==\"ae-43fv6\":\n",
        "    project = rf.workspace(workspace).project(\"damage-severity\")\n",
        "    dataset = project.version(1).download(\"yolov8\")\n",
        "    DATA_FOLDER='Damage-Severity-1'\n",
        "  DATA_YAML_PATH= f\"{HOME}/{DATA_FOLDER}/data.yaml\"\n",
        "elif model_type==\"damage_type\":\n",
        "  if workspace==\"sinfo\":\n",
        "    project = rf.workspace(workspace).project(\"car-damage-type\")\n",
        "    dataset = project.version(1).download(\"yolov8\")\n",
        "    DATA_FOLDER='car-damage-type-1'\n",
        "  elif  workspace==\"fizzy\":\n",
        "    project = rf.workspace(workspace).project(\"damage-type-nbmqw\")\n",
        "    dataset = project.version(3).download(\"yolov8\")\n",
        "    DATA_FOLDER='Damage-Type-3'\n",
        "  elif workspace==\"ae-43fv6\":\n",
        "    project = rf.workspace(workspace).project(\"damage-type-nogzj\")\n",
        "    dataset = project.version(4).download(\"yolov8\")\n",
        "    DATA_FOLDER='Damage-Type-4'\n",
        "elif model_type==\"logo_detection\":\n",
        "  if workspace==\"ae-43fv6\":\n",
        "    project = rf.workspace(workspace).project(\"logo-detection-ccqeh\")\n",
        "    dataset = project.version(2).download(\"yolov8\")\n",
        "    DATA_FOLDER='Logo-Detection-2'\n",
        "  DATA_YAML_PATH= f\"{HOME}/{DATA_FOLDER}/data.yaml\"\n"
      ],
      "metadata": {
        "id": "-6KSPpfndo2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756c0a60-d883-46e9-8c9e-98af64d732e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics<=8.0.20 is required but found version=8.0.80, to fix: `pip install ultralytics<=8.0.20`\n",
            "Downloading Dataset Version Zip in Logo-Detection-1 to yolov8: 100% [73835678 / 73835678] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Logo-Detection-1 in yolov8:: 100%|██████████| 2404/2404 [00:01<00:00, 1500.57it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "# colob_notebook\n",
        "%env CLEARML_API_ACCESS_KEY=AMY0O903Z5A7KN5FETFJ\n",
        "%env CLEARML_API_SECRET_KEY=y7hUwY62xMFWwADGFWzKd33C2b8C4f1AxTDymedak5lQFzmbJg\n",
        "\n",
        "task = Task.init(project_name=PROJECT_NAME, task_name=RUN_NAME)\n"
      ],
      "metadata": {
        "id": "qDxE57EKe8VR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2905e9a-1412-4b79-d1b8-da4ac932b73e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CLEARML_WEB_HOST=https://app.clear.ml\n",
            "env: CLEARML_API_HOST=https://api.clear.ml\n",
            "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
            "env: CLEARML_API_ACCESS_KEY=AMY0O903Z5A7KN5FETFJ\n",
            "env: CLEARML_API_SECRET_KEY=y7hUwY62xMFWwADGFWzKd33C2b8C4f1AxTDymedak5lQFzmbJg\n",
            "ClearML Task: created new task id=5d04c513456a432787199b193866dbc1\n",
            "2023-04-16 19:46:06,242 - clearml.Task - INFO - Storing jupyter notebook directly as code\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML results page: https://app.clear.ml/projects/24f709021bae4238b219ae78c7ed123e/experiments/5d04c513456a432787199b193866dbc1/output/log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX"
      },
      "source": [
        "# Run inference on an image with YOLOv8n-seg\n",
        "#!yolo predict model=yolov8l-seg.pt source='https://ultralytics.com/images/zidane.jpg' box=False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://roboflow.com/?ref=ultralytics\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3ad621-8d8c-4d61-9258-75d34b033bba"
      },
      "source": [
        "# Train YOLOv8l on Custom Data\n",
        "!yolo mode=train \\\n",
        "      model=$WEIGHTS_PATH \\\n",
        "      data=$DATA_YAML_PATH \\\n",
        "      epochs=$EPOCH \\\n",
        "      imgsz=$IMGSZ \\\n",
        "      task=$TASK \\\n",
        "      project=$PROJECT_NAME \\\n",
        "      name=$RUN_NAME \\\n",
        "      batch=$BATCH_SIZE \\\n",
        "      workers=$WORKERS    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-seg.pt to /content/yolov8l-seg.pt...\n",
            "100% 88.1M/88.1M [00:02<00:00, 31.8MB/s]\n",
            "Ultralytics YOLOv8.0.80 🚀 Python-3.9.16 torch-2.0.0+cu118 CPU\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=segment, mode=train, model=/content/yolov8l-seg.pt, data=/content/Logo-Detection-1/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=yolov8_logo_detection, name=train_seg_50_epoch, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=yolov8_logo_detection/train_seg_50_epoch\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 14.4MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.Conv                  [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.C2f                   [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.C2f                   [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.C2f                   [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  ultralytics.nn.modules.C2f                   [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  3   1247744  ultralytics.nn.modules.C2f                   [768, 256, 3]                 \n",
            " 16                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  3   4592640  ultralytics.nn.modules.C2f                   [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   7889779  ultralytics.nn.modules.Segment               [1, 32, 256, [256, 512, 512]] \n",
            "YOLOv8l-seg summary: 401 layers, 45936819 parameters, 45936803 gradients, 220.8 GFLOPs\n",
            "\n",
            "Transferred 651/657 items from pretrained weights\n",
            "WARNING ⚠️ ClearML installed but not initialized correctly, not logging this run. It seems ClearML is not configured on this machine!\n",
            "To get started with ClearML, setup your own 'clearml-server' or create a free account at https://app.clear.ml\n",
            "Setup instructions can be found here: https://clear.ml/docs\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov8_logo_detection/train_seg_50_epoch', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 106 weight(decay=0.0), 117 weight(decay=0.0005), 116 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Logo-Detection-1/train/labels... 1044 images, 108 backgrounds, 0 corrupt: 100% 1044/1044 [00:00<00:00, 1463.16it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Logo-Detection-1/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts not equal\n",
            "/content/Logo-Detection-1/train/images/maruti-suzuki-maruti-suzuki-1000-2016-1726282427_09_jpeg.rf.189316605e931aaa43705448076333a1.jpg:1<>0\n",
            "WARNING ⚠️ Box and segment counts not equal\n",
            "/content/Logo-Detection-1/train/images/maruti-suzuki-maruti-suzuki-1000-2016-1726282427_09_jpeg.rf.c4addbf3363fe108cbe6f4e0094070f0.jpg:1<>0\n",
            "WARNING ⚠️ Box and segment counts not equal\n",
            "/content/Logo-Detection-1/train/images/maruti-suzuki-maruti-suzuki-1000-2016-1726282427_09_jpeg.rf.c895de33288755ed0dbb53c1d8a74260.jpg:1<>0\n",
            "WARNING ⚠️ Box and segment counts not equal\n",
            "/content/Logo-Detection-1/train/images/maruti-suzuki-maruti-suzuki-swift-dzire-tour-2018-1688694932_08_jpeg.rf.2ca00ae8731adf8f8e8427dbf6039bff.jpg:1<>0\n",
            "WARNING ⚠️ Box and segment counts not equal\n",
            "/content/Logo-Detection-1/train/images/maruti-suzuki-maruti-suzuki-swift-dzire-tour-2018-1688694932_08_jpeg.rf.896ecf7a936911b8fc30ff99691490b8.jpg:1<>0\n",
            "WARNING ⚠️ Box and segment counts not equal\n",
            "/content/Logo-Detection-1/train/images/maruti-suzuki-maruti-suzuki-swift-dzire-tour-2018-1688694932_08_jpeg.rf.a7d699264e2c651150a500378a5af111.jpg:1<>0\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 2283, len(boxes) = 2289. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Logo-Detection-1/valid/labels... 98 images, 10 backgrounds, 0 corrupt: 100% 98/98 [00:00<00:00, 1784.19it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/Logo-Detection-1/valid/images/maruti-suzuki-maruti-suzuki-swift-dzire-tour-2018-1688694932_01_jpeg.rf.be3877c6620bb4994eb085febc58ddca.jpg: 2 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Logo-Detection-1/valid/labels.cache\n",
            "Plotting labels to yolov8_logo_detection/train_seg_50_epoch/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1myolov8_logo_detection/train_seg_50_epoch\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/66 [00:21<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 391, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/model.py\", line 367, in train\n",
            "    self.trainer.train()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/trainer.py\", line 190, in train\n",
            "    self._do_train(world_size)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/trainer.py\", line 318, in _do_train\n",
            "    preds = self.model(batch['img'])\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/nn/tasks.py\", line 204, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/nn/tasks.py\", line 58, in _forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/nn/modules.py\", line 205, in forward\n",
            "    y.extend(m(y[-1]) for m in self.m)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/nn/modules.py\", line 205, in <genexpr>\n",
            "    y.extend(m(y[-1]) for m in self.m)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/nn/modules.py\", line 139, in forward\n",
            "    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/nn/modules.py\", line 34, in forward\n",
            "    return self.act(self.bn(self.conv(x)))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "display(Image(filename=f'/content/{PROJECT_NAME}/{RUN_NAME}/confusion_matrix.png'))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "Xub6krqMsf57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training metrics\n",
        "display(Image(filename=f'/content/{PROJECT_NAME}/{RUN_NAME}/results.png'))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "HElCh6QftJXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imageName in glob.glob(f'/content/{PROJECT_NAME}/{RUN_NAME}/train_*.jpg')[:2]:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QPLJEpqXppWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imageName in glob.glob(f'/content/{PROJECT_NAME}/{RUN_NAME}/val_*.jpg')[:2]:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "4q-4bZ6LrQX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Predict\n",
        "Predict a model's accuracy on the dataset's `test` splits. "
      ],
      "metadata": {
        "id": "VF17iJXgtChp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BEST_WEIGHTS_PATH=f'/content/{PROJECT_NAME}/{RUN_NAME}/weights/best.pt'\n",
        "TEST_SOURCE_PATH=f'/content/{DATA_FOLDER}/test/images'\n",
        "\n",
        "!yolo task=$TASK \\\n",
        "      mode=predict \\\n",
        "      model= $BEST_WEIGHTS_PATH \\\n",
        "      source= $TEST_SOURCE_PATH \\\n",
        "      show=False \\\n",
        "      imgsz=$IMGSZ \\\n",
        "      project=$PROJECT_NAME \\\n",
        "      name=$RUN_NAME \\\n",
        "      hide_labels=True \\\n",
        "      conf=0.40 \\\n",
        "      save=True \\\n",
        "      box=False"
      ],
      "metadata": {
        "id": "4XDCTSF8tdLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for imageName in glob.glob(f'/content/{PROJECT_NAME}/{RUN_NAME}/*.jpg')[:5]:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "5Q33ZXT-t9A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kpiRmv66gOZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Export\n",
        "\n",
        "Export a YOLOv8 model to any supported format with the `format` argument, i.e. `format=onnx`.\n",
        "\n",
        "- 💡 ProTip: Export to [ONNX](https://onnx.ai/) or [OpenVINO](https://docs.openvino.ai/latest/index.html) for up to 3x CPU speedup.  \n",
        "- 💡 ProTip: Export to [TensorRT](https://developer.nvidia.com/tensorrt) for up to 5x GPU speedup.\n",
        "\n",
        "\n",
        "| Format                                                                     | `format=`          | Model                     |\n",
        "|----------------------------------------------------------------------------|--------------------|---------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                            | -                  | `yolov8n.pt`              |\n",
        "| [TorchScript](https://pytorch.org/docs/stable/jit.html)                    | `torchscript`      | `yolov8n.torchscript`     |\n",
        "| [ONNX](https://onnx.ai/)                                                   | `onnx`             | `yolov8n.onnx`            |\n",
        "| [OpenVINO](https://docs.openvino.ai/latest/index.html)                     | `openvino`         | `yolov8n_openvino_model/` |\n",
        "| [TensorRT](https://developer.nvidia.com/tensorrt)                          | `engine`           | `yolov8n.engine`          |\n",
        "| [CoreML](https://github.com/apple/coremltools)                             | `coreml`           | `yolov8n.mlmodel`         |\n",
        "| [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model)      | `saved_model`      | `yolov8n_saved_model/`    |\n",
        "| [TensorFlow GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`               | `yolov8n.pb`              |\n",
        "| [TensorFlow Lite](https://www.tensorflow.org/lite)                         | `tflite`           | `yolov8n.tflite`          |\n",
        "| [TensorFlow Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | `edgetpu`          | `yolov8n_edgetpu.tflite`  |\n",
        "| [TensorFlow.js](https://www.tensorflow.org/js)                             | `tfjs`             | `yolov8n_web_model/`      |\n",
        "| [PaddlePaddle](https://github.com/PaddlePaddle)                            | `paddle`           | `yolov8n_paddle_model/`   |\n",
        "\n"
      ],
      "metadata": {
        "id": "nPZZeNrLCQG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=$BEST_WEIGHTS_PATH format=onnx"
      ],
      "metadata": {
        "id": "CYIjW4igCjqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Close clearML experiment\n",
        "task.close()"
      ],
      "metadata": {
        "id": "DIGEnki6uEzK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}