{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/febrahim-driod/hello-world/blob/master/Yolov8_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7527ff1b-0583-4b89-8dd5-d1a8d54b2f9c"
      },
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.55 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 25.4/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "DTjhFMyhdWSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b82bd7c-21bf-4dab-d30a-492919df9929"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow --quiet\n",
        "\n",
        "from roboflow import Roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"P5E6JhfkeiA1nAdZAWnB\")\n",
        "project = rf.workspace(\"sinfo\").project(\"car_damage-4xqh8\")\n",
        "dataset = project.version(6).download(\"yolov8\")\n"
      ],
      "metadata": {
        "id": "-6KSPpfndo2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0320bf3-05de-41b0-b7b4-942d1d2ac36a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics<=8.0.20 is required but found version=8.0.55, to fix: `pip install ultralytics<=8.0.20`\n",
            "Downloading Dataset Version Zip in car_damage-6 to yolov8: 99% [404627456 / 406309644] bytes"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to car_damage-6 in yolov8:: 100%|██████████| 8628/8628 [00:03<00:00, 2509.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clearml --quiet\n",
        "\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "# colob_notebook\n",
        "%env CLEARML_API_ACCESS_KEY=AMY0O903Z5A7KN5FETFJ\n",
        "%env CLEARML_API_SECRET_KEY=y7hUwY62xMFWwADGFWzKd33C2b8C4f1AxTDymedak5lQFzmbJg\n"
      ],
      "metadata": {
        "id": "qDxE57EKe8VR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751397e7-ffb5-46c7-e8f2-120fd66fb3a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/972.3 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m962.6/972.3 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m962.6/972.3 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m972.3/972.3 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25henv: CLEARML_WEB_HOST=https://app.clear.ml\n",
            "env: CLEARML_API_HOST=https://api.clear.ml\n",
            "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
            "env: CLEARML_API_ACCESS_KEY=AMY0O903Z5A7KN5FETFJ\n",
            "env: CLEARML_API_SECRET_KEY=y7hUwY62xMFWwADGFWzKd33C2b8C4f1AxTDymedak5lQFzmbJg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_NAME=\"yolov8_damage_detection\"\n",
        "RUN_NAME=\"train\"\n",
        "\n",
        "from clearml import Task\n",
        "\n",
        "task = Task.init(project_name=PROJECT_NAME, task_name=RUN_NAME)"
      ],
      "metadata": {
        "id": "65bNwW2EnBya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba29491-fc9f-4df0-8d70-297c81c705f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClearML Task: created new task id=adb49ce3aa2c4158a2c014adf6e1cb26\n",
            "ClearML results page: https://app.clear.ml/projects/ae6ddbd949a949299cd90e56ad876556/experiments/adb49ce3aa2c4158a2c014adf6e1cb26/output/log\n",
            "2023-03-22 21:23:06,954 - clearml.Task - INFO - Storing jupyter notebook directly as code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Predict\n",
        "\n",
        "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command for a variety of tasks and modes and accepts additional arguments, i.e. `imgsz=640`. See a full list of available `yolo` [arguments](https://docs.ultralytics.com/usage/cfg/) in the YOLOv8 [Docs](https://docs.ultralytics.com).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362d9372-538d-48e1-ac8b-6762f4d942ca"
      },
      "source": [
        "# Run inference on an image with YOLOv8n-seg\n",
        "!yolo predict model=yolov8m-seg.pt source='https://ultralytics.com/images/zidane.jpg' box=False"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.55 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8m-seg summary (fused): 245 layers, 27268704 parameters, 0 gradients, 110.2 GFLOPs\n",
            "\n",
            "Found https://ultralytics.com/images/zidane.jpg locally at zidane.jpg\n",
            "image 1/1 /content/zidane.jpg: 384x640 3 persons, 2 ties, 36.0ms\n",
            "Speed: 0.7ms preprocess, 36.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS_PATH = f\"{HOME}/yolov8m-seg.pt\"\n",
        "DATA_YAML_PATH= f\"{HOME}/car_damage-6/data.yaml\"\n",
        "TASK='segment'\n",
        "IMGSZ=640\n",
        "BATCH_SIZE=16\n",
        "WORKERS=8\n",
        "EPOCH=50\n",
        "PATIENCE=5"
      ],
      "metadata": {
        "id": "YYADU31VfS9N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "# 3. Train\n",
        "\n",
        "<p align=\"\"><a href=\"https://roboflow.com/?ref=ultralytics\"><img width=\"1000\" src=\"https://github.com/ultralytics/assets/raw/main/yolov8/banner-integrations.png\"/></a></p>\n",
        "\n",
        "Train YOLOv8 on [Detection](https://docs.ultralytics.com/tasks/detect/), [Segmentation](https://docs.ultralytics.com/tasks/segment/) and [Classification](https://docs.ultralytics.com/tasks/classify/) datasets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_YAML_PATH"
      ],
      "metadata": {
        "id": "YQLvqmuJgIkd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "813e54e9-2dd5-47f1-f6c1-36e8d51ae6de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/car_damage-6/data.yaml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40375c4e-7d62-4e12-c056-50fcdda8bd75"
      },
      "source": [
        "# Train YOLOv8m on Custom Data\n",
        "!yolo mode=train \\\n",
        "      model=$WEIGHTS_PATH \\\n",
        "      data=$DATA_YAML_PATH \\\n",
        "      epochs=$EPOCH \\\n",
        "      imgsz=$IMGSZ \\\n",
        "      task=$TASK \\\n",
        "      project=$PROJECT_NAME \\\n",
        "      name=$RUN_NAME \\\n",
        "      batch=$BATCH_SIZE \\\n",
        "      workers=$WORKERS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.55 🚀 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=segment, mode=train, model=/content/yolov8m-seg.pt, data=/content/car_damage-6/data.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=yolov8_damage_detection, name=train, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=yolov8_damage_detection/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 25.8MB/s]\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.Conv                  [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.Conv                  [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.C2f                   [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.Conv                  [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.C2f                   [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.Conv                  [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.C2f                   [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.Conv                  [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.C2f                   [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.SPPF                  [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.C2f                   [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.C2f                   [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.Conv                  [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.C2f                   [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.Conv                  [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.C2f                   [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   5160182  ultralytics.nn.modules.Segment               [2, 32, 192, [192, 384, 576]] \n",
            "YOLOv8m-seg summary: 331 layers, 27240806 parameters, 27240790 gradients, 110.4 GFLOPs\n",
            "\n",
            "Transferred 531/537 items from pretrained weights\n",
            "2023-03-22 21:26:34.315103: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-22 21:26:35.884697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-22 21:26:35.884876: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-03-22 21:26:35.884906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov8_damage_detection/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100% 6.23M/6.23M [00:00<00:00, 67.6MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 86 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/car_damage-6/train/labels... 3016 images, 0 backgrounds, 0 corrupt: 100% 3016/3016 [00:03<00:00, 1004.37it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/car_damage-6/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/car_damage-6/valid/labels... 862 images, 0 backgrounds, 0 corrupt: 100% 862/862 [00:00<00:00, 1062.18it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/car_damage-6/valid/labels.cache\n",
            "Plotting labels to yolov8_damage_detection/train/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov8_damage_detection/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50      8.15G      2.026        4.5      3.525      2.157         65        640:  46% 87/189 [01:32<01:40,  1.01it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "for imageName in glob.glob('/content/PROJECT_NAME/RUN_NAME/train_*.jpg'):\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QPLJEpqXppWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "for imageName in glob.glob('/content/PROJECT_NAME/RUN_NAME/val_*.jpg'):\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "4q-4bZ6LrQX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Predict\n",
        "Predict a model's accuracy on the dataset's `test` splits. "
      ],
      "metadata": {
        "id": "VF17iJXgtChp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=$TASK \\\n",
        "      mode=predict \\\n",
        "      model='/content/PROJECT_NAME/RUN_NAME/weights/best.pt' \\\n",
        "      source='/content/car-damage-segmentation-2/test/images' \\\n",
        "      show=False \\\n",
        "      imgsz=$IMGSZ \\\n",
        "      project=$PROJECT_NAME \\\n",
        "      name=$RUN_NAME \\\n",
        "      hide_labels=True \\\n",
        "      conf=0.25 \\\n",
        "      save=True \\\n",
        "      box=False"
      ],
      "metadata": {
        "id": "4XDCTSF8tdLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "for imageName in glob.glob('/content/yolov8_damage_detection/train2/*.jpg')[90:100]:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")"
      ],
      "metadata": {
        "id": "5Q33ZXT-t9A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Close clearML experiment\n",
        "task.close()"
      ],
      "metadata": {
        "id": "R0bZo4JJ5emI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Export\n",
        "\n",
        "Export a YOLOv8 model to any supported format with the `format` argument, i.e. `format=onnx`.\n",
        "\n",
        "- 💡 ProTip: Export to [ONNX](https://onnx.ai/) or [OpenVINO](https://docs.openvino.ai/latest/index.html) for up to 3x CPU speedup.  \n",
        "- 💡 ProTip: Export to [TensorRT](https://developer.nvidia.com/tensorrt) for up to 5x GPU speedup.\n",
        "\n",
        "\n",
        "| Format                                                                     | `format=`          | Model                     |\n",
        "|----------------------------------------------------------------------------|--------------------|---------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                            | -                  | `yolov8n.pt`              |\n",
        "| [TorchScript](https://pytorch.org/docs/stable/jit.html)                    | `torchscript`      | `yolov8n.torchscript`     |\n",
        "| [ONNX](https://onnx.ai/)                                                   | `onnx`             | `yolov8n.onnx`            |\n",
        "| [OpenVINO](https://docs.openvino.ai/latest/index.html)                     | `openvino`         | `yolov8n_openvino_model/` |\n",
        "| [TensorRT](https://developer.nvidia.com/tensorrt)                          | `engine`           | `yolov8n.engine`          |\n",
        "| [CoreML](https://github.com/apple/coremltools)                             | `coreml`           | `yolov8n.mlmodel`         |\n",
        "| [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model)      | `saved_model`      | `yolov8n_saved_model/`    |\n",
        "| [TensorFlow GraphDef](https://www.tensorflow.org/api_docs/python/tf/Graph) | `pb`               | `yolov8n.pb`              |\n",
        "| [TensorFlow Lite](https://www.tensorflow.org/lite)                         | `tflite`           | `yolov8n.tflite`          |\n",
        "| [TensorFlow Edge TPU](https://coral.ai/docs/edgetpu/models-intro/)         | `edgetpu`          | `yolov8n_edgetpu.tflite`  |\n",
        "| [TensorFlow.js](https://www.tensorflow.org/js)                             | `tfjs`             | `yolov8n_web_model/`      |\n",
        "| [PaddlePaddle](https://github.com/PaddlePaddle)                            | `paddle`           | `yolov8n_paddle_model/`   |\n",
        "\n"
      ],
      "metadata": {
        "id": "nPZZeNrLCQG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model='/content/PROJECT_NAME/RUN_NAME/weights/best.pt' format=onnx"
      ],
      "metadata": {
        "id": "CYIjW4igCjqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Python Usage\n",
        "\n",
        "YOLOv8 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLOv8 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See a detailed Python usage examples in the YOLOv8 [Docs](https://docs.ultralytics.com/usage/python/)."
      ],
      "metadata": {
        "id": "kUMOQ0OeDBJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='coco128.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
        "success = model.export(format='onnx')  # export the model to ONNX format"
      ],
      "metadata": {
        "id": "bpF9-vS_DAaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Tasks\n",
        "\n",
        "YOLOv8 can train, val, predict and export models for the 3 primary tasks in vision AI: detection, segmentation and classification.\n",
        "\n",
        "<img width=\"1024\" src=\"https://user-images.githubusercontent.com/26833433/212094133-6bb8c21c-3d47-41df-a512-81c5931054ae.png\">\n"
      ],
      "metadata": {
        "id": "Phm9ccmOKye5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Detection\n",
        "\n",
        "YOLOv8 _detection_ models have no suffix and are the default YOLOv8 models, i.e. `yolov8n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n"
      ],
      "metadata": {
        "id": "yq26lwpYK1lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
        "model.train(data='coco128.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "8Go5qqS9LbC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Segmentation\n",
        "\n",
        "YOLOv8 _segmentation_ models use the `-seg` suffix, i.e. `yolov8n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n"
      ],
      "metadata": {
        "id": "7ZW58jUzK66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\n",
        "model.train(data='coco128-seg.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "WFPJIQl_L5HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Classification\n",
        "\n",
        "YOLOv8 _classification_ models use the `-cls` suffix, i.e. `yolov8n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n"
      ],
      "metadata": {
        "id": "ax3p94VNK9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
        "model.train(data='mnist160', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "5q9Zu6zlL5rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone install (for development)\n",
        "!git clone https://github.com/ultralytics/ultralytics -b main\n",
        "%pip install -qe ultralytics"
      ],
      "metadata": {
        "id": "uRKlwxSJdhd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMusP4OAxFu6"
      },
      "source": [
        "# Run YOLOv8 tests (git clone install only)\n",
        "!pytest ultralytics/tests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate multiple models\n",
        "for x in 'nsmlx':\n",
        "  !yolo val model=yolov8{x}.pt data=coco.yaml"
      ],
      "metadata": {
        "id": "Wdc6t_bfzDDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}